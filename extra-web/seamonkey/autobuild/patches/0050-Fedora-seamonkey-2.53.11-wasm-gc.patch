#
#  Backport of Mozilla bug 1459761, which (as a side effect) fixes
#  the issues with www.bing.com (cpu hog and crash, as of 20220408)
#
#  Bugs 1340532 and 1389464 (part1 only) are needed as pre-requisites:
#
#    1340532 
#    1389464-1 (only)
#    1459761-1
#    1459761-2
#

diff -Nrup mozilla/js/public/GCAPI.h mozilla-OK/js/public/GCAPI.h
--- mozilla/js/public/GCAPI.h	2022-01-25 01:04:25.000000000 +0300
+++ mozilla-OK/js/public/GCAPI.h	2022-04-07 03:15:23.223246359 +0300
@@ -352,6 +352,7 @@ struct Zone;
     D(FULL_CELL_PTR_BUFFER)                     \
     D(FULL_SLOT_BUFFER)                         \
     D(FULL_SHAPE_BUFFER)                        \
+    D(TOO_MUCH_WASM_MEMORY)                     \
                                                 \
     /* These are reserved for future use. */    \
     D(RESERVED0)                                \
@@ -363,7 +364,6 @@ struct Zone;
     D(RESERVED6)                                \
     D(RESERVED7)                                \
     D(RESERVED8)                                \
-    D(RESERVED9)                                \
                                                 \
     /* Reasons from Firefox */                  \
     D(DOM_WINDOW_UTILS)                         \
diff -Nrup mozilla/js/src/builtin/TestingFunctions.cpp mozilla-OK/js/src/builtin/TestingFunctions.cpp
--- mozilla/js/src/builtin/TestingFunctions.cpp	2022-04-07 05:11:46.024558007 +0300
+++ mozilla-OK/js/src/builtin/TestingFunctions.cpp	2022-04-07 03:00:56.784701745 +0300
@@ -2826,7 +2826,7 @@ static bool
 SharedArrayRawBufferCount(JSContext* cx, unsigned argc, Value* vp)
 {
     CallArgs args = CallArgsFromVp(argc, vp);
-    args.rval().setInt32(SharedArrayRawBuffer::liveBuffers());
+    args.rval().setInt32(LiveMappedBufferCount());
     return true;
 }
 
diff -Nrup mozilla/js/src/jsgc.cpp mozilla-OK/js/src/jsgc.cpp
--- mozilla/js/src/jsgc.cpp	2022-04-07 05:11:46.160557217 +0300
+++ mozilla-OK/js/src/jsgc.cpp	2022-04-07 03:15:23.226246339 +0300
@@ -7378,6 +7378,7 @@ IsDeterministicGCReason(JS::gcreason::Re
       case JS::gcreason::DESTROY_RUNTIME:
       case JS::gcreason::LAST_DITCH:
       case JS::gcreason::TOO_MUCH_MALLOC:
+      case JS::gcreason::TOO_MUCH_WASM_MEMORY:
       case JS::gcreason::ALLOC_TRIGGER:
       case JS::gcreason::DEBUG_GC:
       case JS::gcreason::CC_FORCED:
diff -Nrup mozilla/js/src/vm/ArrayBufferObject.cpp mozilla-OK/js/src/vm/ArrayBufferObject.cpp
--- mozilla/js/src/vm/ArrayBufferObject.cpp	2022-01-25 01:04:29.000000000 +0300
+++ mozilla-OK/js/src/vm/ArrayBufferObject.cpp	2022-04-07 03:59:02.815602514 +0300
@@ -56,11 +56,13 @@
 
 using JS::ToInt32;
 
+using mozilla::Atomic;
 using mozilla::DebugOnly;
 using mozilla::CheckedInt;
 using mozilla::Some;
 using mozilla::Maybe;
 using mozilla::Nothing;
+using mozilla::Unused;
 
 using namespace js;
 using namespace js::gc;
@@ -87,6 +89,163 @@ js::ToClampedIndex(JSContext* cx, Handle
     return true;
 }
 
+// If there are too many 4GB buffers live we run up against system resource
+// exhaustion (address space or number of memory map descriptors), see
+// bug 1068684, bug 1073934 for details.  The limiting case seems to be
+// Windows Vista Home 64-bit, where the per-process address space is limited
+// to 8TB.  Thus we track the number of live objects, and set a limit of
+// 1000 live objects per process and we throw an OOM error if the per-process
+// limit is exceeded.
+//
+// Since the MaximumLiveMappedBuffers limit is not generally accounted for by
+// any existing GC-trigger heuristics, we need an extra heuristic for triggering
+// GCs when the caller is allocating memories rapidly without other garbage.
+// Thus, once the live buffer count crosses a certain threshold, we start
+// triggering GCs every N allocations. As we get close to the limit, perform
+// expensive non-incremental full GCs as a last-ditch effort to avoid
+// unnecessary failure. The *Sans use a ton of vmem for bookkeeping leaving a
+// lot less for the program so use a lower limit.
+
+#if defined(MOZ_TSAN) || defined(MOZ_ASAN)
+static const int32_t MaximumLiveMappedBuffers = 500;
+#else
+static const int32_t MaximumLiveMappedBuffers = 1000;
+#endif
+static const int32_t StartTriggeringAtLiveBufferCount = 100;
+static const int32_t StartSyncFullGCAtLiveBufferCount = MaximumLiveMappedBuffers - 100;
+static const int32_t AllocatedBuffersPerTrigger = 100;
+
+static Atomic<int32_t, mozilla::ReleaseAcquire> liveBufferCount(0);
+static Atomic<int32_t, mozilla::ReleaseAcquire> allocatedSinceLastTrigger(0);
+
+int32_t
+js::LiveMappedBufferCount()
+{
+    return liveBufferCount;
+}
+
+void*
+js::MapBufferMemory(size_t mappedSize, size_t initialCommittedSize)
+{
+    MOZ_ASSERT(mappedSize % gc::SystemPageSize() == 0);
+    MOZ_ASSERT(initialCommittedSize % gc::SystemPageSize() == 0);
+    MOZ_ASSERT(initialCommittedSize <= mappedSize);
+
+    // Test >= to guard against the case where multiple extant runtimes
+    // race to allocate.
+    if (++liveBufferCount >= MaximumLiveMappedBuffers) {
+        if (OnLargeAllocationFailure)
+            OnLargeAllocationFailure();
+        if (liveBufferCount >= MaximumLiveMappedBuffers) {
+            liveBufferCount--;
+            return nullptr;
+        }
+    }
+
+#ifdef XP_WIN
+    void* data = VirtualAlloc(nullptr, mappedSize, MEM_RESERVE, PAGE_NOACCESS);
+    if (!data) {
+        liveBufferCount--;
+        return nullptr;
+    }
+
+    if (!VirtualAlloc(data, initialCommittedSize, MEM_COMMIT, PAGE_READWRITE)) {
+        VirtualFree(data, 0, MEM_RELEASE);
+        liveBufferCount--;
+        return nullptr;
+    }
+#else  // XP_WIN
+    void* data = MozTaggedAnonymousMmap(nullptr, mappedSize, PROT_NONE,
+                                        MAP_PRIVATE | MAP_ANON, -1, 0, "wasm-reserved");
+    if (data == MAP_FAILED) {
+        liveBufferCount--;
+        return nullptr;
+    }
+
+    // Note we will waste a page on zero-sized memories here
+    if (mprotect(data, initialCommittedSize, PROT_READ | PROT_WRITE)) {
+        munmap(data, mappedSize);
+        liveBufferCount--;
+        return nullptr;
+    }
+#endif  // !XP_WIN
+
+#if defined(MOZ_VALGRIND) && defined(VALGRIND_DISABLE_ADDR_ERROR_REPORTING_IN_RANGE)
+    VALGRIND_DISABLE_ADDR_ERROR_REPORTING_IN_RANGE((unsigned char*)data + initialCommittedSize,
+                                                   mappedSize - initialCommittedSize);
+#endif
+
+    return data;
+}
+
+bool
+js::CommitBufferMemory(void* dataEnd, uint32_t delta)
+{
+    MOZ_ASSERT(delta);
+    MOZ_ASSERT(delta % gc::SystemPageSize() == 0);
+
+#ifdef XP_WIN
+    if (!VirtualAlloc(dataEnd, delta, MEM_COMMIT, PAGE_READWRITE))
+        return false;
+#else  // XP_WIN
+    if (mprotect(dataEnd, delta, PROT_READ | PROT_WRITE))
+        return false;
+#endif  // !XP_WIN
+
+#if defined(MOZ_VALGRIND) && defined(VALGRIND_DISABLE_ADDR_ERROR_REPORTING_IN_RANGE)
+    VALGRIND_ENABLE_ADDR_ERROR_REPORTING_IN_RANGE((unsigned char*)dataEnd, delta);
+#endif
+
+    return true;
+}
+
+#ifndef WASM_HUGE_MEMORY
+bool
+js::ExtendBufferMapping(void* dataPointer, size_t mappedSize, size_t newMappedSize)
+{
+    MOZ_ASSERT(mappedSize % gc::SystemPageSize() == 0);
+    MOZ_ASSERT(newMappedSize % gc::SystemPageSize() == 0);
+    MOZ_ASSERT(newMappedSize >= mappedSize);
+
+#ifdef XP_WIN
+    void* mappedEnd = (char*)dataPointer + mappedSize;
+    uint32_t delta = newMappedSize - mappedSize;
+    if (!VirtualAlloc(mappedEnd, delta, MEM_RESERVE, PAGE_NOACCESS))
+        return false;
+    return true;
+#elif defined(XP_LINUX)
+    // Note this will not move memory (no MREMAP_MAYMOVE specified)
+    if (MAP_FAILED == mremap(dataPointer, mappedSize, newMappedSize, 0))
+        return false;
+    return true;
+#else
+    // No mechanism for remapping on MacOS and other Unices. Luckily
+    // shouldn't need it here as most of these are 64-bit.
+    return false;
+#endif
+}
+#endif
+
+void
+js::UnmapBufferMemory(void* base, size_t mappedSize)
+{
+    MOZ_ASSERT(mappedSize % gc::SystemPageSize() == 0);
+
+#ifdef XP_WIN
+    VirtualFree(base, 0, MEM_RELEASE);
+#else  // XP_WIN
+    munmap(base, mappedSize);
+#endif  // !XP_WIN
+
+#if defined(MOZ_VALGRIND) && defined(VALGRIND_ENABLE_ADDR_ERROR_REPORTING_IN_RANGE)
+    VALGRIND_ENABLE_ADDR_ERROR_REPORTING_IN_RANGE((unsigned char*)base, mappedSize);
+#endif
+
+    // Decrement the buffer counter at the end -- otherwise, a race condition
+    // could enable the creation of unlimited buffers.
+    liveBufferCount--;
+}
+
 /*
  * ArrayBufferObject
  *
@@ -540,10 +699,6 @@ class js::WasmArrayRawBuffer
         return maxSize_;
     }
 
-    size_t allocatedBytes() const {
-        return mappedSize_ + gc::SystemPageSize();
-    }
-
 #ifndef WASM_HUGE_MEMORY
     uint32_t boundsCheckLimit() const {
         MOZ_ASSERT(mappedSize_ <= UINT32_MAX);
@@ -563,17 +718,9 @@ class js::WasmArrayRawBuffer
 
         uint8_t* dataEnd = dataPointer() + oldSize;
         MOZ_ASSERT(uintptr_t(dataEnd) % gc::SystemPageSize() == 0);
-# ifdef XP_WIN
-        if (delta && !VirtualAlloc(dataEnd, delta, MEM_COMMIT, PAGE_READWRITE))
-            return false;
-# else  // XP_WIN
-        if (delta && mprotect(dataEnd, delta, PROT_READ | PROT_WRITE))
-            return false;
-# endif  // !XP_WIN
 
-#  if defined(MOZ_VALGRIND) && defined(VALGRIND_DISABLE_ADDR_ERROR_REPORTING_IN_RANGE)
-        VALGRIND_ENABLE_ADDR_ERROR_REPORTING_IN_RANGE((unsigned char*)dataEnd, delta);
-#  endif
+        if (delta && !CommitBufferMemory(dataEnd, delta))
+            return false;
 
         return true;
     }
@@ -585,20 +732,8 @@ class js::WasmArrayRawBuffer
         if (mappedSize_ == newMappedSize)
             return true;
 
-# ifdef XP_WIN
-        uint8_t* mappedEnd = dataPointer() + mappedSize_;
-        uint32_t delta = newMappedSize - mappedSize_;
-        if (!VirtualAlloc(mappedEnd, delta, MEM_RESERVE, PAGE_NOACCESS))
+        if (!ExtendBufferMapping(dataPointer(), mappedSize_, newMappedSize))
             return false;
-# elif defined(XP_LINUX)
-        // Note this will not move memory (no MREMAP_MAYMOVE specified)
-        if (MAP_FAILED == mremap(dataPointer(), mappedSize_, newMappedSize, 0))
-            return false;
-# else
-        // No mechanism for remapping on MacOS and other Unices. Luckily
-        // shouldn't need it here as most of these are 64-bit.
-        return false;
-# endif
 
         mappedSize_ = newMappedSize;
         return true;
@@ -638,33 +773,10 @@ WasmArrayRawBuffer::Allocate(uint32_t nu
     uint64_t mappedSizeWithHeader = mappedSize + gc::SystemPageSize();
     uint64_t numBytesWithHeader = numBytes + gc::SystemPageSize();
 
-# ifdef XP_WIN
-    void* data = VirtualAlloc(nullptr, (size_t) mappedSizeWithHeader, MEM_RESERVE, PAGE_NOACCESS);
+    void* data = MapBufferMemory((size_t) mappedSizeWithHeader, (size_t) numBytesWithHeader);
     if (!data)
         return nullptr;
 
-    if (!VirtualAlloc(data, numBytesWithHeader, MEM_COMMIT, PAGE_READWRITE)) {
-        VirtualFree(data, 0, MEM_RELEASE);
-        return nullptr;
-    }
-# else  // XP_WIN
-    void* data = MozTaggedAnonymousMmap(nullptr, (size_t) mappedSizeWithHeader, PROT_NONE,
-                                        MAP_PRIVATE | MAP_ANON, -1, 0, "wasm-reserved");
-    if (data == MAP_FAILED)
-        return nullptr;
-
-    // Note we will waste a page on zero-sized memories here
-    if (mprotect(data, numBytesWithHeader, PROT_READ | PROT_WRITE)) {
-        munmap(data, mappedSizeWithHeader);
-        return nullptr;
-    }
-# endif  // !XP_WIN
-
-#  if defined(MOZ_VALGRIND) && defined(VALGRIND_DISABLE_ADDR_ERROR_REPORTING_IN_RANGE)
-    VALGRIND_DISABLE_ADDR_ERROR_REPORTING_IN_RANGE((unsigned char*)data + numBytesWithHeader,
-                                                   mappedSizeWithHeader - numBytesWithHeader);
-#  endif
-
     uint8_t* base = reinterpret_cast<uint8_t*>(data) + gc::SystemPageSize();
     uint8_t* header = base - sizeof(WasmArrayRawBuffer);
 
@@ -676,19 +788,11 @@ WasmArrayRawBuffer::Allocate(uint32_t nu
 WasmArrayRawBuffer::Release(void* mem)
 {
     WasmArrayRawBuffer* header = (WasmArrayRawBuffer*)((uint8_t*)mem - sizeof(WasmArrayRawBuffer));
-    uint8_t* base = header->basePointer();
-    MOZ_RELEASE_ASSERT(header->mappedSize() <= SIZE_MAX - gc::SystemPageSize());
 
-# ifdef XP_WIN
-    VirtualFree(base, 0, MEM_RELEASE);
-# else  // XP_WIN
+    MOZ_RELEASE_ASSERT(header->mappedSize() <= SIZE_MAX - gc::SystemPageSize());
     size_t mappedSizeWithHeader = header->mappedSize() + gc::SystemPageSize();
-    munmap(base, mappedSizeWithHeader);
-# endif  // !XP_WIN
 
-#  if defined(MOZ_VALGRIND) && defined(VALGRIND_ENABLE_ADDR_ERROR_REPORTING_IN_RANGE)
-    VALGRIND_ENABLE_ADDR_ERROR_REPORTING_IN_RANGE(base, mappedSizeWithHeader);
-#  endif
+    UnmapBufferMemory(header->basePointer(), mappedSizeWithHeader);
 }
 
 WasmArrayRawBuffer*
@@ -755,9 +859,24 @@ ArrayBufferObject::createForWasm(JSConte
 #endif
     }
 
+    // See MaximumLiveMappedBuffers comment above.
+    if (liveBufferCount > StartSyncFullGCAtLiveBufferCount) {
+        JS::PrepareForFullGC(cx);
+        JS::GCForReason(cx, GC_NORMAL, JS::gcreason::TOO_MUCH_WASM_MEMORY);
+        allocatedSinceLastTrigger = 0;
+    } else if (liveBufferCount > StartTriggeringAtLiveBufferCount) {
+        allocatedSinceLastTrigger++;
+        if (allocatedSinceLastTrigger > AllocatedBuffersPerTrigger) {
+            Unused << cx->runtime()->gc.triggerGC(JS::gcreason::TOO_MUCH_WASM_MEMORY);
+            allocatedSinceLastTrigger = 0;
+        }
+    } else {
+        allocatedSinceLastTrigger = 0;
+    }
+
     auto contents = BufferContents::create<WASM>(wasmBuf->dataPointer());
     buffer->initialize(initialSize, contents, OwnsData);
-    cx->updateMallocCounter(wasmBuf->mappedSize());
+    cx->updateMallocCounter(initialSize);
     return buffer;
 }
 
@@ -1060,8 +1179,6 @@ ArrayBufferObject::create(JSContext* cx,
             size_t nAllocated = nbytes;
             if (contents.kind() == MAPPED)
                 nAllocated = JS_ROUNDUP(nbytes, js::gc::SystemPageSize());
-            else if (contents.kind() == WASM)
-                nAllocated = contents.wasmBuffer()->allocatedBytes();
             cx->updateMallocCounter(nAllocated);
         }
     } else {
diff -Nrup mozilla/js/src/vm/ArrayBufferObject.h mozilla-OK/js/src/vm/ArrayBufferObject.h
--- mozilla/js/src/vm/ArrayBufferObject.h	2021-03-01 21:17:57.000000000 +0300
+++ mozilla-OK/js/src/vm/ArrayBufferObject.h	2022-04-07 03:00:56.785701738 +0300
@@ -23,6 +23,34 @@ namespace js {
 class ArrayBufferViewObject;
 class WasmArrayRawBuffer;
 
+// Create a new mapping of size `mappedSize` with an initially committed prefix
+// of size `initialCommittedSize`.  Both arguments denote bytes and must be
+// multiples of the page size, with `initialCommittedSize` <= `mappedSize`.
+// Returns nullptr on failure.
+void* MapBufferMemory(size_t mappedSize, size_t initialCommittedSize);
+
+// Commit additional memory in an existing mapping.  `dataEnd` must be the
+// correct value for the end of the existing committed area, and `delta` must be
+// a byte amount to grow the mapping by, and must be a multiple of the page
+// size.  Returns false on failure.
+bool CommitBufferMemory(void* dataEnd, uint32_t delta);
+
+#ifndef WASM_HUGE_MEMORY
+// Extend an existing mapping by adding uncommited pages to it.  `dataStart`
+// must be the pointer to the start of the existing mapping, `mappedSize` the
+// size of the existing mapping, and `newMappedSize` the size of the extended
+// mapping (sizes in bytes), with `mappedSize` <= `newMappedSize`.  Both sizes
+// must be divisible by the page size.  Returns false on failure.
+bool ExtendBufferMapping(void* dataStart, size_t mappedSize, size_t newMappedSize);
+#endif
+
+// Remove an existing mapping.  `dataStart` must be the pointer to the start of
+// the mapping, and `mappedSize` the size of that mapping.
+void UnmapBufferMemory(void* dataStart, size_t mappedSize);
+
+// Return the number of currently live mapped buffers.
+int32_t LiveMappedBufferCount();
+
 // The inheritance hierarchy for the various classes relating to typed arrays
 // is as follows.
 //
diff -Nrup mozilla/js/src/vm/Initialization.cpp mozilla-OK/js/src/vm/Initialization.cpp
--- mozilla/js/src/vm/Initialization.cpp	2020-08-10 14:30:35.000000000 +0300
+++ mozilla-OK/js/src/vm/Initialization.cpp	2022-04-07 03:04:44.063008034 +0300
@@ -198,6 +198,7 @@ JS_ShutDown(void)
     if (!JSRuntime::hasLiveRuntimes()) {
         js::wasm::ReleaseBuiltinThunks();
         js::jit::ReleaseProcessExecutableMemory();
+        MOZ_ASSERT(!js::LiveMappedBufferCount());
     }
 
     libraryInitState = InitState::ShutDown;
diff -Nrup mozilla/js/src/vm/SharedArrayObject.cpp mozilla-OK/js/src/vm/SharedArrayObject.cpp
--- mozilla/js/src/vm/SharedArrayObject.cpp	2021-10-26 19:49:54.000000000 +0300
+++ mozilla-OK/js/src/vm/SharedArrayObject.cpp	2022-04-07 03:11:05.823146517 +0300
@@ -10,19 +10,9 @@
 
 #include "jsfriendapi.h"
 #include "jsprf.h"
-
-#ifdef XP_WIN
-# include "jswin.h"
-#endif
 #include "jswrapper.h"
 
 #include "gc/FreeOp.h"
-#ifndef XP_WIN
-# include <sys/mman.h>
-#endif
-#ifdef MOZ_VALGRIND
-# include <valgrind/memcheck.h>
-#endif
 
 #include "jit/AtomicOperations.h"
 #include "vm/SharedMem.h"
@@ -35,46 +25,6 @@
 
 using namespace js;
 
-static inline void*
-MapMemory(size_t length, bool commit)
-{
-#ifdef XP_WIN
-    int prot = (commit ? MEM_COMMIT : MEM_RESERVE);
-    int flags = (commit ? PAGE_READWRITE : PAGE_NOACCESS);
-    return VirtualAlloc(nullptr, length, prot, flags);
-#else
-    int prot = (commit ? (PROT_READ | PROT_WRITE) : PROT_NONE);
-    void* p = mmap(nullptr, length, prot, MAP_PRIVATE | MAP_ANON, -1, 0);
-    if (p == MAP_FAILED)
-        return nullptr;
-    return p;
-#endif
-}
-
-static inline void
-UnmapMemory(void* addr, size_t len)
-{
-#ifdef XP_WIN
-    VirtualFree(addr, 0, MEM_RELEASE);
-#else
-    munmap(addr, len);
-#endif
-}
-
-static inline bool
-MarkValidRegion(void* addr, size_t len)
-{
-#ifdef XP_WIN
-    if (!VirtualAlloc(addr, len, MEM_COMMIT, PAGE_READWRITE))
-        return false;
-    return true;
-#else
-    if (mprotect(addr, len, PROT_READ | PROT_WRITE))
-        return false;
-    return true;
-#endif
-}
-
 // Since this SharedArrayBuffer will likely be used for asm.js code, prepare it
 // for asm.js by mapping the 4gb protected zone described in WasmTypes.h.
 // Since we want to put the SharedArrayBuffer header immediately before the
@@ -90,36 +40,12 @@ SharedArrayMappedSize(uint32_t allocSize
 #endif
 }
 
-// If there are too many 4GB buffers live we run up against system resource
-// exhaustion (address space or number of memory map descriptors), see
-// bug 1068684, bug 1073934 for details.  The limiting case seems to be
-// Windows Vista Home 64-bit, where the per-process address space is limited
-// to 8TB.  Thus we track the number of live objects, and set a limit of
-// 1000 live objects per process; we run synchronous GC if necessary; and
-// we throw an OOM error if the per-process limit is exceeded.
-static mozilla::Atomic<uint32_t, mozilla::ReleaseAcquire> numLive;
-static const uint32_t maxLive = 1000;
-
-#ifdef DEBUG
-static mozilla::Atomic<int32_t> liveBuffers_;
-#endif
-
 static uint32_t
 SharedArrayAllocSize(uint32_t length)
 {
     return AlignBytes(length + gc::SystemPageSize(), gc::SystemPageSize());
 }
 
-int32_t
-SharedArrayRawBuffer::liveBuffers()
-{
-#ifdef DEBUG
-    return liveBuffers_;
-#else
-    return 0;
-#endif
-}
-
 SharedArrayRawBuffer*
 SharedArrayRawBuffer::New(JSContext* cx, uint32_t length)
 {
@@ -135,51 +61,17 @@ SharedArrayRawBuffer::New(JSContext* cx,
     bool preparedForAsmJS = jit::JitOptions.asmJSAtomicsEnable && IsValidAsmJSHeapLength(length);
 
     void* p = nullptr;
-    if (preparedForAsmJS) {
-        // Test >= to guard against the case where multiple extant runtimes
-        // race to allocate.
-        if (++numLive >= maxLive) {
-            if (OnLargeAllocationFailure)
-                OnLargeAllocationFailure();
-            if (numLive >= maxLive) {
-                numLive--;
-                return nullptr;
-            }
-        }
-
-        uint32_t mappedSize = SharedArrayMappedSize(allocSize);
-
-        // Get the entire reserved region (with all pages inaccessible)
-        p = MapMemory(mappedSize, false);
-        if (!p) {
-            numLive--;
-            return nullptr;
-        }
-
-        if (!MarkValidRegion(p, allocSize)) {
-            UnmapMemory(p, mappedSize);
-            numLive--;
-            return nullptr;
-        }
-
-# if defined(MOZ_VALGRIND) && defined(VALGRIND_DISABLE_ADDR_ERROR_REPORTING_IN_RANGE)
-        // Tell Valgrind/Memcheck to not report accesses in the inaccessible region.
-        VALGRIND_DISABLE_ADDR_ERROR_REPORTING_IN_RANGE((unsigned char*)p + allocSize,
-                                                       mappedSize - allocSize);
-# endif
-    } else {
-        p = MapMemory(allocSize, true);
-        if (!p)
-            return nullptr;
-    }
+    if (preparedForAsmJS)
+        p = MapBufferMemory(SharedArrayMappedSize(allocSize), allocSize);
+    else
+        p = MapBufferMemory(allocSize, allocSize);
+    if (!p)
+        return nullptr;
 
     uint8_t* buffer = reinterpret_cast<uint8_t*>(p) + gc::SystemPageSize();
     uint8_t* base = buffer - sizeof(SharedArrayRawBuffer);
     SharedArrayRawBuffer* rawbuf = new (base) SharedArrayRawBuffer(buffer, length, preparedForAsmJS);
     MOZ_ASSERT(rawbuf->length == length); // Deallocation needs this
-#ifdef DEBUG
-    liveBuffers_++;
-#endif
     return rawbuf;
 }
 
@@ -213,31 +105,15 @@ SharedArrayRawBuffer::dropReference()
         return;
 
     // If this was the final reference, release the buffer.
-
-#ifdef DEBUG
-    liveBuffers_--;
-#endif
-
     SharedMem<uint8_t*> p = this->dataPointerShared() - gc::SystemPageSize();
     MOZ_ASSERT(p.asValue() % gc::SystemPageSize() == 0);
 
     uint8_t* address = p.unwrap(/*safe - only reference*/);
     uint32_t allocSize = SharedArrayAllocSize(this->length);
-
-    if (this->preparedForAsmJS) {
-        numLive--;
-
-        uint32_t mappedSize = SharedArrayMappedSize(allocSize);
-        UnmapMemory(address, mappedSize);
-
-# if defined(MOZ_VALGRIND) && defined(VALGRIND_ENABLE_ADDR_ERROR_REPORTING_IN_RANGE)
-        // Tell Valgrind/Memcheck to recommence reporting accesses in the
-        // previously-inaccessible region.
-        VALGRIND_ENABLE_ADDR_ERROR_REPORTING_IN_RANGE(address, mappedSize);
-# endif
-    } else {
-        UnmapMemory(address, allocSize);
-    }
+    if (this->preparedForAsmJS)
+        UnmapBufferMemory(address, SharedArrayMappedSize(allocSize));
+    else
+        UnmapBufferMemory(address, allocSize);
 }
 
 
